# 从程序员到架构师：大数据量、缓存、高并发、微服务、多团队协同等核心场景实战

- 作者：王伟杰
- 出版社：机械工业出版社
- 出版时间：2022-03
- ISBN：978-7-5097-6324-7
- 豆瓣：https://book.douban.com/subject/35834352
- 在线：https://book.qq.com/book-read/44175269/14
- 封面：

![](../../../../image/2024/11/978-7-111-69984-2.jpg)

# 第1部分 数据持久化层场景实战

## 第1章 冷热分离

### 1.1 业务场景：几千万数据量的工单表如何快速优化

这次项目优化的是一个邮件客服系统。它是一个SaaS（通过网络提供软件服务）系统，但是大客户只有两三家，最主要的客户是一家大型媒体集团。

这个系统的主要功能是这样的：它会对接客户的邮件服务器，自动收取发到几个特定客服邮箱的邮件，每收到一封客服邮件，就自动生成一个工单。之后系统就会根据一些规则将工单分派给不同的客服专员处理。

这个系统是支持多租户的，每个租户使用自己的数据库（MySQL）。

这家媒体集团客户两年多产生了近2000万的工单，工单的操作记录近1亿。

平时客服在工单页面操作时，打开或者刷新工单列表需要10秒钟左右。

该客户当时做了一个业务上的变更，增加了几个客服邮箱，然后把原来不进入邮件客服系统的一些客户邮件的接收人改为这几个新增加的客服邮箱，并接入这个系统。

发生这个业务变更以后，工单数量急剧增长，工单列表打开的速度越来越慢，后来客服的负责人发了封邮件，言辞急切，要求尽快改善性能。

项目组收到邮件后，详细分析了一下当时的数据状况，情况如下：

1. 工单表已经达到3000万条数据。
2. 工单表的处理记录表达到1.5亿条数据。
3. 工单表每日以10万的数据量在增长。

当时系统性能已经严重影响了客服的处理效率，需要放在第一优先级解决，客户给的期限是1周。

### 1.2 数据库分区，从学习到放弃

数据库分区有以下优点：

1. 比起单个文件系统或硬盘，分区可以存储更多的数据。
2. 在清理数据时，可以直接删除废弃数据所在的分区。同样，有新数据时，可以增加更多的分区来存储新数据。
3. 可以大幅度地优化特定的查询，让这些查询语句只去扫描特定分区的数据。比如，原来有2000万的数据，设计10个分区，每个分区存200万的数据，那么可以优化查询语句，让它只去查询其中两个分区，即只需要扫描400万的数据。

第3个优点正好可以解决此处的项目需求。但是，要怎么设计分区字段？也就是说，要根据什么来分区？

MySQL的分区还有个限制，即分区字段必须是唯一索引（主键也是唯一索引）的一部分。工单表是用ticketID当主键，也就是说接下来无论使用什么当分区字段，都必须把它加到主键当中，形成复合主键。MySQL官方文档原文如下：

> All columns used in the partitioning expression for a partitioned table must be part of every unique key that the table may have.
>
> In other words,every unique key on the table must use every column in the table's partitioning expression（This also includes the table's primary key, since it is by definition a unique key.This particular case is discussed later in this section）.

接着深入分析一下业务流程：

1. 系统从邮件服务器同步到邮件以后，创建一个工单，createdTime就是工单创建的时间。
2. 客服先去查询无处理人的工单，然后把工单分派给自己。
3. 客服处理工单，每处理一次，系统自动增加一条处理记录。
4. 客服处理完工单以后，将工单状态改为“关闭”。

通过跟客服的交流，项目组发现，一般工单被关闭以后，客服查询的概率就很低了。对于那些关闭超过一个月的工单，基本上一年都打开不了几次。

调研到这里，基本的思路是增加一个状态：归档。首先将关闭超过一个月以上的工单自动转为“归档”状态，然后将数据库分为两个区，所有“归档”状态的工单存放在一个区，所有非“归档”状态的工单存放在另外一个区，最后在所有的查询语句中加一个条件，就是状态不等于“归档”。

简单估算一下：客服频繁操作的工单基本上都是1个月内的工单，按照后期一天10万来算，也就是300万的数据，这样数据库的非归档区基本就没什么压力了。

那么，是否就将status设为分区字段，然后直接使用MySQL的分区功能？不是的。

因为相关的开发人员并没有用过数据库分区的功能，而当时面临的情况是只有1周的时间来解决问题，并且工单表是系统最核心的数据表，不能出问题。

这种情况下，没人敢在生产的核心功能上使用一项没用过的技术，但是项目组评估了一下，要实现一个类似的方案，其实工作量并不大，而且代码可控。因此，项目组放弃了数据库分区，并决定基于同样的分区理念，使用自己熟悉的技术来实现这个功能。

这个思路也很简单：新建一个数据库，然后将1个月前已经完结的工单数据都移动到这个新的数据库。这个数据库就叫冷库，因为里面基本是冷数据（当然，叫作归档数据库也可以），之后极少被访问。当前的数据库保留正常处理的较新的工单数据，这是热库。

这样处理后，因为客服查询的基本是近期常用的数据，大概只有300万条，性能就基本没问题了。即使因为查询频繁，或者几个客服同时查询，也不会再像之前那样出现数据库占满CPU、整个系统几乎宕机的情况了。

上面这个方法，其实就是软件系统常用的“冷热分离”。

### 1.3 冷热分离简介

#### 1.3.1 什么是冷热分离

冷热分离就是在处理数据时将数据库分成冷库和热库，冷库存放那些走到终态、不常使用的数据，热库存放还需要修改、经常使用的数据。

#### 1.3.2 什么情况下使用冷热分离

假设业务需求出现了以下情况，就可以考虑使用冷热分离的解决方案。

1. 数据走到终态后只有读没有写的需求，比如订单完结状态。
2. 用户能接受新旧数据分开查询，比如有些电商网站默认只让查询3个月内的订单，如果要查询3个月前的订单，还需要访问其他的页面。

### 1.4 冷热分离一期实现思路：冷热数据都用MySQL

当决定用冷热分离之后，项目组就开始考虑使用一个性价比最高的冷热分离方案。因为资源有限、工期又短，冷热分离一期有一个主导原则，即热数据跟冷数据使用一样的存储（MySQL）和数据结构，这样工作量最少，等到以后有时间再做冷热分离二期

问题：

1. 如何判断一个数据是冷数据还是热数据？
2. 如何触发冷热数据分离？
3. 如何实现冷热数据分离？
4. 如何使用冷热数据？
5. 历史数据如何迁移？

#### 1.4.1 如何判断一个数据到底是冷数据还是热数据

一般而言，在判断一个数据到底是冷数据还是热数据时，主要采用主表里一个字段或多个字段的组合作为区分标识。

这个字段可以是时间维度，比如“下单时间”，可以把3个月前的订单数据当作冷数据，3个月内的订单数据当作热数据。

当然，这个字段也可以是状态维度，比如根据“订单状态”字段来区分，将已完结的订单当作冷数据，未完结的订单当作热数据。

还可以采用组合字段的方式来区分，比如把下单时间小于3个月且状态为“已完结”的订单标识为冷数据，其他的当作热数据。

关于判断冷热数据的逻辑，这里还有两个要点必须说明。

1. 如果一个数据被标识为冷数据，业务代码不会再对它进行写操作。
2. 不会同时存在读取冷、热数据的需求。

#### 1.4.2 如何触发冷热数据分离

一般来说，冷热数据分离的触发逻辑分为3种。

1）直接修改业务代码，使得每次修改数据时触发冷热分离（比如每次更新订单的状态时，就去触发这个逻辑）

2）如果不想修改原来的业务代码，可以通过监听数据库变更日志binlog的方式来触发

3）通过定时扫描数据库的方式来触发

下面给出它们各自的优缺点：

![](../../../../image/2024/11/28_01.jpg "表1-2 3种触发逻辑的优缺点")

根据以上对比，可以得出每种触发逻辑的建议场景。

1.修改写操作的业务代码

建议在业务代码比较简单，并且不按照时间区分冷热数据时使用。

场景示例：假设是根据订单的状态来区分冷热数据，订单的状态不会随着时间自动变化，必须有人去修改才会变化，并且很容易找出所有修改订单状态的业务代码，这种情况下可以用这种触发逻辑。

2.监听数据库变更日志

建议在业务代码比较复杂，不能随意变更，并且不按时间区分冷热数据时使用。

示例场景跟上一场景类似：假设是根据订单的状态来区分冷热数据，订单的状态不会随着时间自动变化，必须有人去修改才会变化。其不一样的地方在于，业务代码很复杂，特别是有些用了很多年的系统中，修改订单状态的代码分布在多个位置，甚至多个服务中，不可能都找到，并且因为难以评估影响面，所以修改起来风险很大。这种情况下就适合使用监听数据库变更日志的方式。

3.定时扫描数据库

建议在按照时间区分冷热数据时使用。

示例场景就是这个项目中的业务场景。这里的业务需求是已经关闭超过1个月的工单视为冷数据，这种场景下，工单变更的那一瞬间，即使工单已经关闭了，也不能将其视为冷数据，而必须再等待1个月。这样的情况非常适合使用定时扫描。

所以这一次，项目组就选用了定时扫描数据库的触发方式。但是对于不同项目自身的场景，到底选择哪种触发方式，还是需要根据具体业务需求来决定。

#### 1.4.3 如何分离冷热数据


分离冷热数据的基本逻辑：

1. 判断数据是冷是热
2. 将要分离的数据插入冷数据库中
3. 从热数据库中删除分离的数据

实际做方案时，以下3点都要考虑在内：

这里提到的一致性要求是指如何保证任何一步出错后数据最终还是一致的。任何一个程序都要考虑在运行过程中突然出错中断时，应该怎么办。业务逻辑如下。

1.一致性：同时修改多个数据库，如何保证数据的一致性？

1. 找出符合冷数据的工单
2. 将这些工单添加到冷数据库
3. 将这些工单从热数据库中删除

这里的解决方案为，保证每一步都可以重试且操作都有幂等性，具体逻辑分为4步。

1. 在热数据库中给需要迁移的数据加标识：ColdFlag=WaittingForMove
2. 找出所有待迁移的数据（ColdFlag=WaittingForMove）
3. 在冷数据库中保存一份数据，但在保存逻辑中需要加个判断来保证幂等性
4. 从热数据库中删除对应的数据

2.数据量：假设数据量大，一次处理不完，该怎么办？是否需要使用批量处理？

假设每次可以迁移1000条数据。

1. 在热数据库中给需要的数据添加标识：ColdFlag=WaittingForMove。这个过程使用Update语句就可以完成，每次更新大概10万条记录
2. 找出前1000条待迁移的数据（ColdFlag=WaittingForMove）
3. 在冷数据库中保存一份数据
4. 从热数据库中删除对应的数据
5. 循环执行2）~4）

3.并发性：假设数据量大到要分到多个地方并行处理，该怎么办？

#### 1.4.4 如何使用冷热数据

#### 1.4.5 历史数据如何迁移

### 1.5 冷热分离二期实现思路：冷数据存放到HBase

#### 1.5.1 冷热分离一期解决方案的不足

冷热分离一期的解决方案确实能解决写操作慢和热数据慢的问题，但仍然存在诸多不足。

1. 用户查询冷数据的速度依旧很慢，虽然查询冷数据的用户比例很低
2. 冷数据库偶尔会告警

#### 1.5.2 归档工单的使用场景

对于归档的工单，与客服沟通后发现，基本只有以下几个查询动作。

1. 根据客户的邮箱查询归档工单
2. 根据工单ID查出该工单所有的处理记录

这些操作转化成技术需求就是：需要找到一个数据库，它可以满足下面的要求。

1. 可以存放上亿甚至数亿的数据。因为按照一年3000多万的工单来看，3年以后工单表的数据就上亿了，工单处理记录表的数据也会多出几亿
2. 支持简单的组合关键字查询，查询慢一些可以接受
3. 存放的数据不再需要变更。基于这个特性，就可以将历史工单的详情数据封装在一个文档中，类似于Key-Value，Key就是工单ID，Value就是工单详情数据

最后，项目组决定使用HBase来保存归档工单

## 第2章 查询分离

上一场景使用的冷热分离解决方案性价比高，可以快速交付，但它却不是一个最优的方案，仍然存在诸多不足。比如，业务功能上要求不能再修改冷数据，查询冷数据速度慢，无法承受复杂的查询和统计。

### 2.1 业务场景：千万工单表如何实现快速查询

本场景中的客服系统承接的是集团的所有业务，每条业务线的客服又分为多个渠道，有电话、在线聊天、微信、微博等。

它的业务流程是这样的：当客户接线进来以后，不管是通过什么渠道，客服都会登记一个客服工单，而后再根据业务线、工单的类型来登记不同的信息；工单创建后，会按需创建其他的单据，比如退款单、投诉单、充值单等，针对每个该工单的处理动作或工单关联单据的处理动作，也会自动添加工单处理记录和更新处理时间。

系统已经运作了5年左右，已有数据量大，而且随着集团业务的扩大，业务线增加，客服增多，工单数量的增长也越来越快，在系统中查询工单，以及打开工单详情的时候，就会出现响应速度很慢的情况。

项目组调研了查询慢和工单详情打开慢的问题，具体情况如下。

1. 查询慢。当时工单数据库里面有1000万左右的客服工单时，每次查询时需要关联其他近10个表，一次查询平均花费13秒左右
2. 打开工单慢。工单打开以后需要调用多个接口，分别将用户信息、订单信息以及其他客服创建的单据信息列出来（如退款、赔偿、充值、投诉等）。打开工单详情页需要近5秒

还有个思路：读写分离：MySQL有个主从架构，可以将所有对工单表的写操作转入MySQL的主库，所有对工单表的查询操作连接到MySQL的从库。读写分离的好处就是，读的请求和写的请求针对不同的数据库，彼此不会抢占数据库资源。而且，主库用InnoDB的存储引擎，从库用MyISM，MyISM不支持事务，但是性能更好。但是，使用这个方案得到的工单查询速度提升有限，所以最终没有采用。

### 2.2 查询分离简介

#### 2.2.1 何为查询分离

每次写数据时保存一份数据到其他的存储系统里，用户查询数据时直接从中获取数据


#### 2.2.2 何种场景下使用查询分离

1. 数据量大：比如单个表的行数有上千万，当然，如果几百万就出现查询慢的问题，也可以考虑使用
2. 查询数据的响应效率很低：因为表数据量大，或者关联查询太过复杂，导致查询很慢的情况
3. 所有写数据请求的响应效率尚可：虽然查询慢，但是写操作的响应速度还可以接受的情况
4. 所有数据任何时候都可能被修改和查询：这一点是针对冷热分离的，因为如果有些数据走入终态就不再用到，就可以归档到冷数据库了，不一定要用查询分离这个方案

### 2.3 查询分离实现思路

#### 2.3.1 如何触发查询分离

查询分离的触发逻辑分为3种

1. 修改业务代码，在写入常规数据后同步更新查询数据
2. 修改业务代码，在写入常规数据后，异步更新查询数据
3. 监控数据库日志，如有数据变更，则更新查询数据

3种触发逻辑的优缺点

![](../../../../image/2024/11/48_03.jpg "表2-1 3种触发逻辑的优缺点")

3种触发逻辑的适用场景

![](../../../../image/2024/11/49_01.jpg "表2-2 3种触发逻辑的适用场景")


基于考虑，项目组最后选择了第2种方案：修改所有与工单写操作有关的业务代码，在更新完工单数据后，异步触发更新查询数据的逻辑，而后不等查询数据更新完成，就直接返回结果给客服。

#### 2.3.2 如何实现查询分离

问题5：消息的时序性问题。

比如某个订单A更新了一次数据变成A1，线程甲将A1的数据迁移到查询数据中。不一会儿，后台订单A又更新了一次数据变成A2，线程乙也启动工作，将A2的数据迁移到查询数据中。

此时解决方案为主数据每次更新时，都更新上次更新的时间last_update_time，然后每个线程更新查询数据后，检查当前工单A的last_update_time是否与线程刚开始获得的时间相同，以及NeedUpdateQueryData是否等于false，如果都满足，就将NeedUpdateQueryData改为true，然后再做一次迁移。

#### 2.3.3 查询数据如何存储

Elasticsearch

#### 2.3.4 查询数据如何使用

因Elasticsearch自带API，所以使用查询数据时，在查询业务代码中直接调用Elasticsearch的API即可。

不过要考虑一个场景：数据查询更新完前，查询数据不一致怎么办？举一个例子：假设更新工单的操作可以在100毫秒内完成，但是将新的工单同步到Elasticsearch需要2秒，那么在这2秒内，如果用户去查询，就可能查询到旧的工单数据。

这里分享两种解决思路。

1. 在查询数据更新到最新前，不允许用户查询。笔者团队没用过这种方案，但在其他实际项目中见到过
2. 给用户提示：“您目前查询到的数据可能是2秒前的数据，如果发现数据不准确，可以尝试刷新一下。”这种提示用户一般都能接受

#### 2.3.5 历史数据迁移

在这个方案里，只需要把所有的历史数据加上标识NeedUpdateQueryData=true，程序就会自动处理了。

#### 2.3.6 MQ+Elasticsearch的整体方案

1. 使用异步方式触发查询数据的同步。当工单修改后，会异步启动一个线程来同步工单数据到查询数据库
2. 通过MQ来实现异步的效果。MQ还做了两件事：①服务的解耦，将工单主业务系统和查询系统的服务解耦；②削峰，当修改工单的并发请求太多时，通过MQ控制同步查询数据库的线程数，防止查询数据库的同步请求太大
3. 将工单的查询数据存储在Elasticsearch中。因为Elasticsearch是一个分布式索引系统，天然就是用来做大数据的复杂查询的
4. 因为查询数据同步到Elasticsearch会有一定的延时，所以用户可能会查询到旧的工单数据，所以要给用户一些提示
5. 关于历史数据的迁移，因为是用字段NeedUpdateQueryData来标识工单是否需要同步，所以只要把所有历史数据的标识改成true，系统就会自动批量将历史数据同步到Elasticsearch

### 2.4 Elasticsearch注意事项

客观地说，Elasticsearch确实是个好工具，毕竟它在分布式开源搜索和分析引擎中处于领先地位。不过它也存在不少陷阱，以至于身边几个朋友经常抱怨Elasticsearch有多么不好用。

这里总结一些关于Elasticsearch的使用要点。

1. 如何使用Elasticsearch设计表结构？
2. Elasticsearch的存储结构。
3. Elasticsearch如何修改表结构？
4. Elasticsearch的准实时性。
5. Elasticsearch可能丢数据。
6. Elasticsearch分页。

#### 2.4.1 如何使用Elasticsearch设计表结构

Elasticsearch是基于索引的设计，它无法像MySQL那样使用join查询，所以查询数据时需要把每条主数据及关联子表的数据全部整合在一条记录中。

#### 2.4.2 Elasticsearch的存储结构

Elasticsearch是一个分布式的查询系统，它的每一个节点都是一个基于Lucene的查询引擎。下面通过与MySQL的概念对比来更快地理解Lucene。

1.Lucene和MySQL的概念对比

Lucene是一个索引系统，此处把Lucene与MySQL的一些概念做简单对照，见表2-4。


![](../../../../image/2024/11/57_02.jpg "表2-4 Lucene与MySQL概念对照")

2.无结构文档的倒排索引

Lucene使用的是倒排索引的结构

假如有一些无结构的文档，见表2-5。

![](../../../../image/2024/11/58_01.jpg "表2-5 无结构文档")

简单倒排索引后显示的结果见表2-6。

![](../../../../image/2024/11/58_02.jpg "表2-6 倒排索引")

3.有结构文档的倒排索引

比如每个Doc都有多个Field，Field有不同的值（包含不同的Term），见表2-7。

![](../../../../image/2024/11/58_03.jpg "表2-7 有结构文档的倒排索引")

倒排表见表2-8~表2-10。

![](../../../../image/2024/11/59_01.jpg "表2-8 性别倒排索引")


![](../../../../image/2024/11/59_02.jpg "表2-9 年龄倒排索引")


![](../../../../image/2024/11/59_03.jpg "表2-10 武功倒排索引")

有结构的文档经过倒排索引后，字段中的每个值都是一个关键字，存放在Term Dictionary（词汇表）中，且每个关键字都有对应地址指向所在文档。

4.Elasticsearch的Document如何定义结构和字段格式？

#### 2.4.3 Elasticsearch如何修改表结构

如果想增加新的字段，Elasticsearch可以支持直接添加。因为修改字段的类型会导致索引失效，所以Elasticsearch不支持修改原来字段的类型。

如果想修改字段的映射，首先需要新建一个索引，然后使用Elasticsearch的reindex功能将旧索引复制到新索引中。

#### 2.4.4 陷阱一：Elasticsearch是准实时的吗

当更新数据至Elasticsearch且返回成功提示时，会发现通过Elasticsearch查询返回的数据仍然不是最新的，背后的原因究竟是什么？

因数据索引的整个过程涉及Elasticsearch的Shard（分片），以及Lucene Index、Segment、Document三者之间的关系等知识点，所以有必要先对这些内容进行说明。

因数据索引的整个过程涉及Elasticsearch的Shard（分片），以及Lucene Index、Segment、Document三者之间的关系等知识点，所以有必要先对这些内容进行说明。

Elasticsearch的一个Shard（Elasticsearch分片的具体介绍可参考官方文档）就是一个Lucene Index（索引），每一个Lucene Index由多个Segment（段）构成，即Lucene Index的子集就是Segment，如图2-9所示。

Lucene Index、Segment、Document（Doc）三者之间的关系如图2-10所示。

通过图2-10可以知道，一个Lucene Index可以存放多个Segment，而每个Segment又可以存放多个Document。


![](../../../../image/2024/11/63_01.jpg "图2-9 分片（Shard）结构图")

![](../../../../image/2024/11/63_02.jpg "图2-10 Index、Segment、Document三者之间的关系")

1. 当新的Document被创建时，数据首先会存放到新的Segment中，同时旧的Document会被删除，并在原来的Segment上标记一个删除标识。当Document被更新时，旧版Document会被标识为删除，并将新版Document存放在新的Segment中
2. Shard收到写请求时，请求会被写入Translog中，然后Document被存放在Memory Buffer（内存缓冲区）中，最终Translog保存所有修改记录，如图2-11所示
3. 每隔1秒（默认设置），Refresh（刷新）操作被执行一次，且Memory Buffer中的数据会被写入一个Segment，并存放在File System Cache（文件系统缓存）中，这时新的数据就可以被搜索到了，如图2-12所示

![](../../../../image/2024/11/64_01.jpg "图2-11 写请求处理示意图")

![](../../../../image/2024/11/64_02.jpg "图2-12 Refresh操作示意图")

通过以上数据索引过程的说明，可以发现Elasticsearch并不是实时的，而是有1秒延时。延时问题的解决方案在前面介绍过，提示用户查询的数据会有一定延时即可。


#### 2.4.5 陷阱二：Elasticsearch宕机恢复后，数据丢失

上一小节中提及每隔1秒（根据配置）Memory Buffer中的数据会被写入Segment中，此时这部分数据可被用户搜索到，但没有持久化，一旦系统宕机，数据就会丢失，如图2-12最右边的桶所示。

如何防止数据丢失呢？使用Lucene中的Commit操作就能轻松解决这个问题。

Commit操作方法：先将多个Segment合并保存到磁盘中，再将灰色的桶变成图2-12中蓝色的桶。

使用Commit操作存在一点不足：耗费I/O，从而引发Elasticsearch在Commit之前宕机的问题。一旦系统在Translog执行fsync函数之前宕机，数据也会直接丢失，如何保证Elasticsearch数据的完整性便成了亟待解决的问题。


遇到这种情况，通过Translog解决即可，因为Translog中的数据不会直接保存在磁盘中，只有使用fsync函数后才会保存。具体实现方式有两种。

1. 将index.translog.durability设置成request，其缺点就是耗费资源，性能差一些，如果发现启用这个配置后系统运行得不错，采用这种方式即可
2. 将index.translog.durability设置为fsync，每次Elasticsearch宕机启动后，先将主数据和Elasticsearch数据进行对比，再将Elasticsearch缺失的数据找出来

#### 2.4.6 陷阱三：分页越深，查询效率越低

Elasticsearch分页这个陷阱的出现，与Elasticsearch读操作请求的处理流程密切关联，如图2-13所示。

Elasticsearch的读操作流程主要分为两个阶段：Query Phase、Fetch Phase。

1. Query Phase：协调的节点先把请求分发到所有分片，然后每个分片在本地查询后建一个结果集队列，并将命令中的Document ID以及搜索分数存放在队列中，再返回给协调节点，最后协调节点会建一个全局队列，归并收到的所有结果集并进行全局排序。

> 在Elasticsearch查询过程中，如果search方法带有from和size参数，Elasticsearch集群需要给协调节点返回分片数*（from+size）条数据，然后在单机上进行排序，最后给客户端返回size大小的数据。比如客户端请求10条数据，有3个分片，那么每个分片会返回10条数据，协调节点最后会归并30条数据，但最终只返回10条数据给客户端。

2. Fetch Phase：协调节点先根据结果集里的Document ID向所有分片获取完整的Document，然后所有分片返回完整的Document给协调节点，最后协调节点将结果返回给客户端。


![](../../../../image/2024/11/66_01.jpg "图2-13 Elasticsearch读操作示意图")

比如有5个分片，需要查询排序序号从10000到10010（from=10000，size=10）的结果，每个分片到底返回多少数据给协调节点计算呢？不是10条，是10010条。也就是说，协调节点需要在内存中计算10010*5=50050条记录，所以在系统使用中，用户分页越深查询速度会越慢，也就是说分页并不是越多越好。

那如何更好地解决Elasticsearch分页问题呢？为了控制性能，可以使用Elas-ticsearch中的max_result_window进行配置，这个数据默认为10000，当from+size>max result window时，Elasticsearch将返回错误。

这个配置就是要控制用户翻页不能太深，而这在现实场景中用户也能接受，本项目的方案就采用了这种设计方式。如果用户确实有深度翻页的需求，使用Elasticsearch中search_after的功能也能解决，只是无法实现跳页了。

### 2.5 小结

1. 使用Elasticsearch存储查询数据时，就要接受上面列出的一些局限性：有一定延时，深度分页不能自由跳页，会有丢数据的可能性
2. 主数据量越来越大后，写操作还是慢，到时还是会出问题。比如这里的工单数据，虽然已经去掉了所有外键，但是当数据量上亿的时候，插入还是会有问题
3. 主数据和查询数据不一致时，如果业务逻辑需要查询数据保持一致性呢？这里的查询数据同步到最新数据会有一定的延时，大约为2秒。某些业务场景下用户可能无法接受这个延时，特别是跟钱有关的场景

架构“没有银弹”，不能期望一个解决方案既能覆盖所有的问题，还能实现最小的成本损耗
